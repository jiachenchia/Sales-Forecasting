{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbae15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Subcluster data\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Loading Master Store Subcluster file\n",
    "df_subcluster = pd.read_csv(r\" ... csv\")\n",
    "\n",
    "# Select and rename the required columns for Master Store Subcluster\n",
    "selected_columns = {\n",
    "    'Location Code': 'Store_No',\n",
    "    'Name': 'Name',\n",
    "    'CLOSEDATE': 'CLOSEDATE',\n",
    "    'Opening Date': 'Opening_Date',\n",
    "    'State': 'State',\n",
    "    'CODE': 'CODE (subcluster 1)',\n",
    "    'CODE FY26 1': 'CODE FY26 1 (subcluster 2)',\n",
    "    'CODE FY26 2': 'CODE FY26 2 (subcluster 3)'\n",
    "}\n",
    "df_subcluster_selected = df_subcluster[list(selected_columns.keys())].rename(columns=selected_columns)\n",
    "\n",
    "# Ensure correct datetime format for Opening_Date and CLOSEDATE\n",
    "df_subcluster_selected[\"Opening_Date\"] = pd.to_datetime(df_subcluster_selected[\"Opening_Date\"], errors=\"coerce\")\n",
    "df_subcluster_selected[\"CLOSEDATE\"] = pd.to_datetime(df_subcluster_selected[\"CLOSEDATE\"], errors=\"coerce\")  \n",
    "# errors = \"coerce\"= \"If a value can't be converted to a date, don't raise an error—just set it to NaT (Not a Time).\"\n",
    "\n",
    "# Filtering outliers\n",
    "# 1. Closed stores: where CLOSEDATE is NOT null (i.e. already closed)\n",
    "closed_stores = df_subcluster_selected[df_subcluster_selected[\"CLOSEDATE\"].notna()][\"Store_No\"].astype(str)\n",
    "\n",
    "# 2. Not open yet: where Opening_Date is in the future\n",
    "today = pd.Timestamp.today().normalize()\n",
    "not_open_yet = df_subcluster_selected[df_subcluster_selected[\"Opening_Date\"] > today][\"Store_No\"].astype(str)\n",
    "\n",
    "# 3. Empty Name: where Name is missing or blank\n",
    "empty_name = df_subcluster_selected[df_subcluster_selected[\"Name\"].isna() | (df_subcluster_selected[\"Name\"].str.strip() == \"\")][\"Store_No\"].astype(str)\n",
    "\n",
    "# Combine all outlier Store_Nos and changing to integer\n",
    "outliers = pd.concat([closed_stores, not_open_yet, empty_name]).unique().tolist()\n",
    "outliers_int = set(int(x) for x in outliers)\n",
    "\n",
    "# Remove outliers from main dataset\n",
    "df_subcluster_clean = df_subcluster_selected[~df_subcluster_selected[\"Store_No\"].astype(int).isin(outliers_int)]\n",
    "\n",
    "# Creating new column \"Days after Opening\"\n",
    "df_subcluster_clean['Days_after_Opening'] = (datetime.today() - df_subcluster_clean['Opening_Date']).dt.days\n",
    "\n",
    "# Creating duplicated rows with different dates from opening date to now\n",
    "# Create an empty list to hold the expanded rows\n",
    "expanded_rows = []\n",
    "\n",
    "# Iterate over each row\n",
    "for _, row in df_subcluster_clean.iterrows():\n",
    "    opening_date = row['Opening_Date']\n",
    "    if pd.isna(opening_date):\n",
    "        continue  # Skip rows with invalid dates\n",
    "    \n",
    "    today = datetime.today().date()\n",
    "    date_range = pd.date_range(start=opening_date, end=today)\n",
    "    \n",
    "    for i, date in enumerate(date_range):\n",
    "        new_row = row.to_dict()\n",
    "        new_row['Date'] = date\n",
    "        new_row['Days_after_Opening'] = i\n",
    "        expanded_rows.append(new_row)\n",
    "\n",
    "# Create the expanded DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Obtain only 2022-12-25 to 2025-06-17 data (weather data only up until then)\n",
    "expanded_df = expanded_df[\n",
    "    (expanded_df[\"Date\"] >= \"2022-12-25\") &\n",
    "    (expanded_df[\"Date\"] <  \"2025-06-17\")\n",
    "]\n",
    "\n",
    "# Ensure date formats match\n",
    "expanded_df['Date'] = pd.to_datetime(expanded_df['Date'])\n",
    "\n",
    "# Dropping \"CLOSEDATE\" column\n",
    "expanded_df = expanded_df.drop(columns=[\"CLOSEDATE\", \"Name\"])\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Sales data\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Loading Daily Sales Data\n",
    "daily_sales = pd.read_csv(r\" ... csv\")\n",
    "\n",
    "# Renaming columns so it matches the other merged data\n",
    "daily_sales.rename(columns={\n",
    "    \"Store No\": \"Store_No\",\n",
    "    \"Net Amount\": \"Net_Amount\"\n",
    "}, inplace=True)\n",
    "\n",
    "## Keep only rows where Store_No is purely numeric - V is for vending machines\n",
    "# Clean, then filter\n",
    "daily_sales[\"Store_No\"] = daily_sales[\"Store_No\"].astype(str).str.strip()\n",
    "\n",
    "# Filter purely numeric store numbers\n",
    "sales_stores = daily_sales[daily_sales[\"Store_No\"].str.fullmatch(r\"\\d+\")].copy()\n",
    "\n",
    "# Convert to integer after filtering\n",
    "sales_stores[\"Store_No\"] = sales_stores[\"Store_No\"].astype(int) \n",
    "\n",
    "# Convert date to datetime\n",
    "sales_stores[\"Date\"] = pd.to_datetime(sales_stores[\"Date\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "# Changing / format to - format\n",
    "sales_stores[\"Date\"] = sales_stores[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Convert date to datetime\n",
    "sales_stores[\"Date\"] = pd.to_datetime(sales_stores[\"Date\"]) #, dayfirst=True, errors=\"coerce\"\n",
    "\n",
    "# Change columns to desired object types\n",
    "sales_stores[\"Net_Amount\"] = sales_stores[\"Net_Amount\"].astype(float)\n",
    "sales_stores[\"TC\"] = sales_stores[\"TC\"].astype(int)\n",
    "\n",
    "# Obtain only 2022-12-25 to 2025-06-17\n",
    "sales_stores = sales_stores[\n",
    "    (sales_stores[\"Date\"] >= \"2022-12-25\") &\n",
    "    (sales_stores[\"Date\"] <  \"2025-06-17\")\n",
    "]\n",
    "\n",
    "# Remove outliers from dataset\n",
    "sales_stores = sales_stores[~sales_stores[\"Store_No\"].astype(int).isin(outliers_int)]\n",
    "\n",
    "sales_stores = sales_stores[sales_stores[\"TC\"] >= 50]\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Merge sales data to public subcluster data \n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Making sure merged data Store_No is also int\n",
    "expanded_df[\"Store_No\"] = expanded_df[\"Store_No\"].astype(int) \n",
    "\n",
    "# Joining to create the final df - Weather, Store & Clusters, Public Holiday & (finally) Sales\n",
    "df_subcluster_sales = pd.merge(sales_stores[[\"Date\", \"Store_No\", \"Net_Amount\", \"TC\"]], expanded_df[[\"Store_No\",\"Opening_Date\",\"State\",\"CODE (subcluster 1)\",\"CODE FY26 1 (subcluster 2)\",\n",
    "                                                                                                    \"CODE FY26 2 (subcluster 3)\",\"Days_after_Opening\", \"Date\"]],on=[\"Date\", \"Store_No\"],how=\"left\")\n",
    "\n",
    "# Flip the sign of the amount\n",
    "df_subcluster_sales[\"Net_Amount\"] *= -1\n",
    "\n",
    "# Taking only rows with Days after Opening data (filtering out test transactions)\n",
    "df_subcluster_sales = df_subcluster_sales[df_subcluster_sales[\"Days_after_Opening\"].notna()]\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Weather data\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Load Weather Data Updated\n",
    "wx = pd.read_csv(r\" ... csv\")\n",
    "\n",
    "# Standardising time, Date and Hour\n",
    "wx[\"ts_utc\"] = pd.to_datetime(wx[\"Timestamp\"].str.strip(), format=\"%Y-%m-%d %H:%M:%S%z\", utc=True)\n",
    "wx[\"ts_sg\"]  = wx[\"ts_utc\"].dt.tz_convert(\"Asia/Singapore\")\n",
    "wx[\"Date\"]   = wx[\"ts_sg\"].dt.date\n",
    "wx[\"Hour\"]   = wx[\"ts_sg\"].dt.hour\n",
    "\n",
    "# Changing Store_No to integer\n",
    "wx[\"Store_No\"] = wx[\"Store No\"].astype(int)\n",
    "\n",
    "# Selecting only columns that we need\n",
    "wx = wx[[\"Date\",\"Hour\",\"Store_No\",\"Weather Code\",\"Temperature (°C)\"]]\n",
    "\n",
    "# Obtain only 2022-12-25 to 2027-01-01 data (weather data only up until 2025-06-17)\n",
    "wx = wx[\n",
    "    (wx[\"Date\"] >= pd.to_datetime(\"2022-12-25\").date()) &\n",
    "    (wx[\"Date\"] <  pd.to_datetime(\"2027-01-01\").date())\n",
    "]\n",
    "\n",
    "# Creating Column \"Rain?\"\n",
    "# Define code groups as integers\n",
    "valid_clear_codes = {0, 1, 2, 3}\n",
    "rain_codes = {51, 53, 55, 61, 63, 65}\n",
    "\n",
    "# Group and apply logic directly on integers\n",
    "wx_daily = wx.groupby([\"Store_No\", \"Date\"], as_index=False).agg({\n",
    "    \"Temperature (°C)\": \"mean\",\n",
    "    \"Weather Code\": lambda codes: (\n",
    "        \"Yes\" if any(code in rain_codes for code in codes)\n",
    "        else \" No\" if all(code in valid_clear_codes for code in codes)\n",
    "        else \"Error\"\n",
    "    )\n",
    "})\n",
    "\n",
    "# Rename columns\n",
    "wx_daily.rename(columns={\n",
    "    \"Weather Code\": \"Rain?\",\n",
    "    \"Temperature (°C)\": \"Average Daily Temperature (°C)\"\n",
    "}, inplace=True)\n",
    "\n",
    "wx_daily[\"Date\"] = pd.to_datetime(wx_daily[\"Date\"], format=\"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "# Filtering out outliers\n",
    "wx_daily = wx_daily[~wx_daily[\"Store_No\"].astype(int).isin(outliers_int)].copy()\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Merging weather data on subcluster and sales data\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "merged_df = pd.merge(df_subcluster_sales, wx_daily, on=['Store_No', 'Date'], how='left')\n",
    "\n",
    "# Filter: Keep rows where store was already open on that date\n",
    "merged_df = merged_df[merged_df[\"Date\"] >= merged_df[\"Opening_Date\"]]\n",
    "\n",
    "# Optional: Drop rows where key store details are still missing\n",
    "critical_columns = [\"State\", \"CODE FY26 1 (subcluster 2)\", \"CODE FY26 2 (subcluster 3)\", \"Days_after_Opening\"] \n",
    "#not \"CODE (subcluster 1)\" as contains some stores that opened during 2024/2025 when the labelling is not up to date\n",
    "merged_df = merged_df.dropna(subset=critical_columns)\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 6) Public holiday data\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Load the public holiday data\n",
    "public_holiday_df = pd.read_excel(r\"C:\\Users\\chiaj\\OneDrive\\Desktop\\FM Project\\PH for non-PH.xlsx\")\n",
    "\n",
    "# Fix datetime formats\n",
    "public_holiday_df['Date'] = pd.to_datetime(public_holiday_df['Date'])\n",
    "public_holiday_df['Opening_Date'] = pd.to_datetime(public_holiday_df['Opening_Date'])  # Fix: not the same as Date\n",
    "\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
    "merged_df['Opening_Date'] = pd.to_datetime(merged_df['Opening_Date'])\n",
    "\n",
    "# Merge only on essential keys\n",
    "merged_ph_weather_subcluster_sales_df = pd.merge(\n",
    "    merged_df,\n",
    "    public_holiday_df[['Date', 'Store_No', 'Name', 'Puasa', 'Public Holiday']],\n",
    "    on=['Date', 'Store_No'],\n",
    "    how='left'  # preserve all rows from your main dataset\n",
    ")\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 7) Merging public holiday data on weather, subcluster, sales data\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# New Day column\n",
    "merged_ph_weather_subcluster_sales_df['Day'] = merged_ph_weather_subcluster_sales_df['Date'].dt.day_name()\n",
    "\n",
    "# New Month column\n",
    "merged_ph_weather_subcluster_sales_df['Month'] = merged_ph_weather_subcluster_sales_df['Date'].dt.month_name()\n",
    "\n",
    "merged_ph_weather_subcluster_sales_df['Date'] = pd.to_datetime(merged_ph_weather_subcluster_sales_df['Date'])\n",
    "merged_ph_weather_subcluster_sales_df.to_csv(r\" ... csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
