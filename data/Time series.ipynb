{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adcca9a7",
   "metadata": {},
   "source": [
    "From Master Weather + Store Subcluster + Holiday + Sales, take days from holiday 0 only (let model learn +- 7). remove everything else. then drop days from holiday column. also categorise holidays: race-related celebrations, sultan birthdays, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f431076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "# Loading dataset\n",
    "df_phclusterweather = pd.read_csv(r\" ... csv\") \n",
    "daily_sales = pd.read_csv(r\" ... csv\")\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Preparing Data for Time Series\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "df_holiday_days = df_phclusterweather[df_phclusterweather[\"Days From Holiday\"] == 0.0]\n",
    "df_holiday_days = df_holiday_days.drop(columns = \"Days From Holiday\")\n",
    "\n",
    "PH_categories = [\n",
    "    \"International Celebrations\",\n",
    "    \"Race/Religion-related Celebrations\",\n",
    "    \"Leader's Birthdays\",\n",
    "    \"Regional Independence Holidays\",\n",
    "    \"Puasa\"\n",
    "    \"Others\"\n",
    "]\n",
    "\n",
    "def categorize_holiday(name):\n",
    "    name_lower = name.lower()\n",
    "    \n",
    "    # Leader's Birthdays (includes Prophet's Birthday and Almarhum Sultan)\n",
    "    if re.search(r\"(birthday|coronation)\", name_lower) or \"almarhum sultan iskandar\" in name_lower:\n",
    "        return \"Leader's Birthdays\"\n",
    "\n",
    "    # Race/Religion-related Celebrations (merged group)\n",
    "    elif re.search(r\"(chinese|thaipusam|gawai|harvest|deepavali|isra|ramadan|good friday|quran|aidilfitri|arafat|haji|muharram|wesak|prophet)\", name_lower):\n",
    "        return \"Race/Religion-related Celebrations\"\n",
    "\n",
    "    # International Celebrations\n",
    "    elif re.search(r\"(new year|valentine|labour|christmas)\", name_lower):\n",
    "        return \"International Celebrations\"\n",
    "\n",
    "    # Region Independence Holidays\n",
    "    elif re.search(r\"(national day|federal territory|independence)\", name_lower):\n",
    "        return \"Regional Independence Holidays\"\n",
    "\n",
    "    # Puasa\n",
    "    elif re.search(r\"(puasa)\", name_lower):\n",
    "        return \"Puasa\"\n",
    "    \n",
    "    # Others\n",
    "    else:\n",
    "        return \"Others\"\n",
    "\n",
    "df_holiday_days[\"Name\"] = df_holiday_days[\"Name\"].apply(categorize_holiday)\n",
    "\n",
    "# Dropping Puasa duplicates - 520 rows\n",
    "df_holiday_nodupe = df_holiday_days.drop_duplicates()\n",
    "\n",
    "# Puasa column\n",
    "df_holiday_nodupe[\"Puasa\"] = (df_holiday_nodupe[\"Puasa Count\"] != 0).astype(int)\n",
    "\n",
    "# Making sure all rows with the same date have 1 if its during Puasa\n",
    "df_holiday_nodupe[\"Puasa\"] = (\n",
    "    df_holiday_nodupe.groupby(\"Date\")[\"Puasa\"].transform(\"max\")\n",
    ")\n",
    "\n",
    "# Step 1: Count number of unique holiday names per (Date, Store_No)\n",
    "holiday_counts = df_holiday_nodupe.groupby([\"Date\", \"Store_No\"])[\"Name\"].nunique()\n",
    "\n",
    "# Step 2: Identify keys where multiple holidays exist\n",
    "multi_holiday_keys = holiday_counts[holiday_counts > 1].index\n",
    "\n",
    "# Step 3: Drop \"Puasa\" rows where other holidays exist for that store/date\n",
    "mask = (df_holiday_nodupe[\"Name\"] == \"Puasa\") & (df_holiday_nodupe.set_index([\"Date\", \"Store_No\"]).index.isin(multi_holiday_keys))\n",
    "df_cleaned = df_holiday_nodupe[~mask].copy()\n",
    "\n",
    "### To check which dates have duplicate rows (rows with 2 different public holidays that is not Puasa)\n",
    "# # 1. Group by Date and Store_No, count unique holiday Names\n",
    "# multi_name_counts = df_cleaned.groupby([\"Date\", \"Store_No\"])[\"Name\"].nunique()\n",
    "\n",
    "# # 2. Filter for groups with more than 1 holiday\n",
    "# multi_holiday_days = multi_name_counts[multi_name_counts > 1]\n",
    "\n",
    "# # 3. Reset index to view as DataFrame\n",
    "# multi_holiday_days = multi_holiday_days.reset_index().rename(columns={\"Name\": \"Holiday_Count\"})\n",
    "\n",
    "# unique_dates = sorted(multi_holiday_days[\"Date\"].unique())\n",
    "# print(unique_dates)\n",
    "\n",
    "df_cleaned2 = df_cleaned.drop(columns=[\"Puasa Count\"])\n",
    "\n",
    "df_group = df_cleaned2.groupby([\"Date\", \"Store_No\"]).agg({\n",
    "    \"Name\": lambda x: \", \".join(sorted(set(x))),\n",
    "    \"Net_Amount\": \"first\",\n",
    "    \"TC\": \"first\",\n",
    "    \"State\": \"first\",\n",
    "    \"Opening_Date\": \"first\",\n",
    "    \"CODE (subcluster 1)\": \"first\",\n",
    "    \"CODE FY26 1 (subcluster 2)\": \"first\",\n",
    "    \"CODE FY26 2 (subcluster 3)\": \"first\",\n",
    "    \"Days_after_Opening\": \"first\",\n",
    "    \"Average Daily Temperature (°C)\": \"first\",\n",
    "    \"Rain?\": \"first\",\n",
    "    \"Puasa\": \"first\",\n",
    "    \"Public Holiday\": \"max\"  # since PH values are 0s and 1s\n",
    "}).reset_index()\n",
    "\n",
    "# Dropping Net_Amount and TC to repopulate them with daily sales data (currently on sales data for PH, need include non-PH sales data too)\n",
    "df_no_net_no_tc = df_group.drop(columns=[\"Net_Amount\",\"TC\"])\n",
    "\n",
    "### Cleaning daily sales data\n",
    "# Renaming columns so it matches the other merged data\n",
    "daily_sales.rename(columns={\n",
    "    \"Store No\": \"Store_No\",\n",
    "    \"Net Amount\": \"Net_Amount\"\n",
    "}, inplace=True)\n",
    "\n",
    "## Keep only rows where Store_No is purely numeric - V is for vending machines\n",
    "# Clean, then filter\n",
    "daily_sales[\"Store_No\"] = daily_sales[\"Store_No\"].astype(str).str.strip()\n",
    "\n",
    "# Filter purely numeric store numbers\n",
    "sales_stores = daily_sales[daily_sales[\"Store_No\"].str.fullmatch(r\"\\d+\")].copy()\n",
    "\n",
    "# Convert to integer after filtering\n",
    "sales_stores[\"Store_No\"] = sales_stores[\"Store_No\"].astype(int) \n",
    "\n",
    "# Convert date to datetime\n",
    "sales_stores[\"Date\"] = pd.to_datetime(sales_stores[\"Date\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "# Changing / format to - format\n",
    "sales_stores[\"Date\"] = sales_stores[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Convert date to datetime\n",
    "sales_stores[\"Date\"] = pd.to_datetime(sales_stores[\"Date\"]) #, dayfirst=True, errors=\"coerce\"\n",
    "\n",
    "# Change columns to desired object types\n",
    "sales_stores[\"Net_Amount\"] = sales_stores[\"Net_Amount\"].astype(float)\n",
    "sales_stores[\"TC\"] = sales_stores[\"TC\"].astype(int)\n",
    "\n",
    "# Obtain only 2022-12-25 to 2027-01-01\n",
    "sales_stores = sales_stores[\n",
    "    (sales_stores[\"Date\"] >= \"2022-12-25\") &\n",
    "    (sales_stores[\"Date\"] <  \"2027-01-01\")\n",
    "]\n",
    "\n",
    "# Dropping columns we don't need \n",
    "sales_stores_cleaned = sales_stores.drop(columns=[\"Date.Month\",\"Discount\",\"Sales Day\"])\n",
    "\n",
    "# Change to desired object types\n",
    "df_no_net_no_tc[\"Date\"] = pd.to_datetime(df_no_net_no_tc[\"Date\"]) #, dayfirst=True, errors=\"coerce\"\n",
    "df_no_net_no_tc[\"Name\"] = df_no_net_no_tc[\"Name\"].astype(str)\n",
    "df_no_net_no_tc[\"State\"] = df_no_net_no_tc[\"State\"].astype(str)\n",
    "df_no_net_no_tc[\"Opening_Date\"] = pd.to_datetime(df_no_net_no_tc[\"Opening_Date\"])\n",
    "df_no_net_no_tc[\"CODE (subcluster 1)\"] = df_no_net_no_tc[\"CODE (subcluster 1)\"].astype(str)\n",
    "df_no_net_no_tc[\"CODE FY26 1 (subcluster 2)\"] = df_no_net_no_tc[\"CODE FY26 1 (subcluster 2)\"].astype(str)\n",
    "df_no_net_no_tc[\"CODE FY26 2 (subcluster 3)\"] = df_no_net_no_tc[\"CODE FY26 2 (subcluster 3)\"].astype(str)\n",
    "df_no_net_no_tc[\"Days_after_Opening\"] = df_no_net_no_tc[\"Days_after_Opening\"].astype(int)\n",
    "df_no_net_no_tc[\"Rain?\"] = df_no_net_no_tc[\"Rain?\"].astype(str)\n",
    "df_no_net_no_tc[\"Public Holiday\"] = df_no_net_no_tc[\"Public Holiday\"].astype(int)\n",
    "\n",
    "# Merging final dataframe\n",
    "df_final = pd.merge(df_no_net_no_tc, sales_stores_cleaned, on=[\"Store_No\",\"Date\",\"Name\",\"State\",\"Opening_Date\",\"CODE (subcluster 1)\",\"CODE FY26 1 (subcluster 2)\",\"CODE FY26 2 (subcluster 3)\"\n",
    "                                                               \"Days_after_Opening\",\"Average Daily Temperature (°C)\",\"Rain?\",\"Puasa SET TO ZERO\",\"Public Holiday SET TO ZERO\"], how=\"left\")\n",
    "\n",
    "df_final.to_excel(r\" ... xlsx\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
